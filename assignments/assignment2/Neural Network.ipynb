{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer, softmax_with_cross_entropy, l2_regularization\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from assignment1.linear_classifer import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"../assignment1/data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLULayer:\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        # TODO: Implement forward pass\n",
    "        # Hint: you'll need to save some information about X\n",
    "        # to use it later in the backward pass\n",
    "        self.X = np.copy(X)\n",
    "        output = self._reLU(self.X)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _reLU(self, x):\n",
    "        x[x < 0] = 0\n",
    "        return x\n",
    "    \n",
    "    def backward(self, d_out):\n",
    "        \"\"\"\n",
    "        Backward pass\n",
    "\n",
    "        Arguments:\n",
    "        d_out, np array (batch_size, num_features) - gradient\n",
    "           of loss function with respect to output\n",
    "\n",
    "        Returns:\n",
    "        d_result: np array (batch_size, num_features) - gradient\n",
    "          with respect to input\n",
    "        \"\"\"\n",
    "        # TODO: Implement backward pass\n",
    "        # Your final implementation shouldn't have any loops\n",
    "\n",
    "        d_result = d_out * self._grad_reLU(self.X)\n",
    "\n",
    "        return d_result\n",
    "    \n",
    "    def _grad_reLU(self, x):\n",
    "        x[x > 0] = 1\n",
    "        x[x < 0] = 0\n",
    "        return x\n",
    "\n",
    "    def params(self):\n",
    "        # ReLU Doesn't have any parameters\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2, 3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param:\n",
    "    \"\"\"\n",
    "    Trainable parameter of the model\n",
    "    Captures both parameter value and the gradient\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.grad = np.zeros_like(value)\n",
    "        \n",
    "\n",
    "class FullyConnectedLayer:\n",
    "    def __init__(self, n_input, n_output):\n",
    "        self.W = Param(0.001 * np.random.randn(n_input, n_output))\n",
    "        self.B = Param(0.001 * np.random.randn(1, n_output))\n",
    "        self.X = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        # TODO: Implement forward pass\n",
    "        # Your final implementation shouldn't have any loops\n",
    "        self.X = X\n",
    "        return self.X @ self.W.value + self.B.value\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        \"\"\"\n",
    "        Backward pass\n",
    "        Computes gradient with respect to input and\n",
    "        accumulates gradients within self.W and self.B\n",
    "\n",
    "        Arguments:\n",
    "        d_out, np array (batch_size, n_output) - gradient\n",
    "           of loss function with respect to output\n",
    "\n",
    "        Returns:\n",
    "        d_result: np array (batch_size, n_input) - gradient\n",
    "          with respect to input\n",
    "        \"\"\"\n",
    "        # TODO: Implement backward pass\n",
    "        # Compute both gradient with respect to input\n",
    "        # and gradients with respect to W and B\n",
    "        # Add gradients of W and B to their `grad` attribute\n",
    "\n",
    "        # It should be pretty similar to linear classifier from\n",
    "        # the previous assignment\n",
    "        d_result = d_out @ self.W.value.T\n",
    "        self.W.grad = self.X.T @ d_out\n",
    "        self.B.grad = np.ones((self.B.value.shape[0], self.X.shape[0])) @ d_out\n",
    "        \n",
    "        return d_result\n",
    "\n",
    "    def params(self):\n",
    "        return {'W': self.W, 'B': self.B}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    \"\"\" Neural network with two fully connected layers \"\"\"\n",
    "\n",
    "    def __init__(self, n_input, n_output, hidden_layer_size, reg):\n",
    "        \"\"\"\n",
    "        Initializes the neural network\n",
    "\n",
    "        Arguments:\n",
    "        n_input, int - dimension of the model input\n",
    "        n_output, int - number of classes to predict\n",
    "        hidden_layer_size, int - number of neurons in the hidden layer\n",
    "        reg, float - L2 regularization strength\n",
    "        \"\"\"\n",
    "        self.reg = reg\n",
    "        # TODO Create necessary layers\n",
    "        self.fc1 = FullyConnectedLayer(n_input, hidden_layer_size)\n",
    "        self.relu1 = ReLULayer()\n",
    "        self.fc2 = FullyConnectedLayer(hidden_layer_size, n_output)\n",
    "\n",
    "    def compute_loss_and_gradients(self, X, y):\n",
    "        \"\"\"\n",
    "        Computes total loss and updates parameter gradients\n",
    "        on a batch of training examples\n",
    "\n",
    "        Arguments:\n",
    "        X, np array (batch_size, input_features) - input data\n",
    "        y, np array of int (batch_size) - classes\n",
    "        \"\"\"\n",
    "        # Before running forward and backward pass through the model,\n",
    "        # clear parameter gradients aggregated from the previous pass\n",
    "        # TODO Set parameter gradient to zeros\n",
    "        # Hint: using self.params() might be useful!\n",
    "        self._zero_grad()\n",
    "        \n",
    "        # TODO Compute loss and fill param gradients\n",
    "        # by running forward and backward passes through the model\n",
    "        predictions = self._forward(X)\n",
    "        loss, dprediction = softmax_with_cross_entropy(predictions, y)\n",
    "        self._backward(dprediction)\n",
    "        \n",
    "        # After that, implement l2 regularization on all params\n",
    "        # Hint: self.params() is useful again!\n",
    "        loss_l2 = self._backward_l2_regularization()\n",
    "        loss += loss_l2\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def _zero_grad(self):\n",
    "        for param in self.params().values():\n",
    "            param.grad = np.zeros_like(param.value)\n",
    "                \n",
    "    def _forward(self, X):\n",
    "        output = self.fc1.forward(X)\n",
    "        output = self.relu1.forward(output)\n",
    "        output = self.fc2.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def _backward(self, dprediction):\n",
    "        grad = self.fc2.backward(dprediction)\n",
    "        grad = self.relu1.backward(grad)\n",
    "        self.fc1.backward(grad)\n",
    "        \n",
    "    def _backward_l2_regularization(self):\n",
    "        loss_l2 = 0.\n",
    "        \n",
    "        for param in self.params().values():\n",
    "            param_loss_l2, param_grad_l2 = l2_regularization(param.value, self.reg)\n",
    "            param.grad += param_grad_l2\n",
    "            loss_l2 += param_loss_l2\n",
    "                \n",
    "        return loss_l2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Produces classifier predictions on the set\n",
    "\n",
    "        Arguments:\n",
    "          X, np array (test_samples, num_features)\n",
    "\n",
    "        Returns:\n",
    "          y_pred, np.array of int (test_samples)\n",
    "        \"\"\"\n",
    "        # TODO: Implement predict\n",
    "        # Hint: some of the code of the compute_loss_and_gradients\n",
    "        # can be reused\n",
    "        pred = np.zeros(X.shape[0], np.int)\n",
    "\n",
    "        predictions = self._forward(X)\n",
    "        y_pred = np.argmax(softmax(predictions), axis=1)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def params(self):\n",
    "        result = {}\n",
    "\n",
    "        # TODO Implement aggregating all of the params\n",
    "        for k, v in self.fc2.params().items():\n",
    "            result[\"\".join([\"fc2_\", k])] = v\n",
    "        \n",
    "        for k, v in self.fc1.params().items():\n",
    "            result[\"\".join([\"fc1_\", k])] = v\n",
    "            \n",
    "\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for fc2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2_B\n",
      "Gradient check passed!\n",
      "Checking gradient for fc1_W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc1_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for fc2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2_B\n",
      "Gradient check passed!\n",
      "Checking gradient for fc1_W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc1_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "from metrics import multiclass_accuracy\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Utility class to hold training and validation data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_X, train_y, val_X, val_y):\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "        self.val_X = val_X\n",
    "        self.val_y = val_y\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Trainer of the neural network models\n",
    "    Perform mini-batch SGD with the specified data, model,\n",
    "    training parameters and optimization rule\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, dataset, optim,\n",
    "                 num_epochs=20,\n",
    "                 batch_size=20,\n",
    "                 learning_rate=1e-2,\n",
    "                 learning_rate_decay=1.0):\n",
    "        \"\"\"\n",
    "        Initializes the trainer\n",
    "\n",
    "        Arguments:\n",
    "        model - neural network model\n",
    "        dataset, instance of Dataset class - data to train on\n",
    "        optim - optimization method (see optim.py)\n",
    "        num_epochs, int - number of epochs to train\n",
    "        batch_size, int - batch size\n",
    "        learning_rate, float - initial learning rate\n",
    "        learning_rate_decal, float - ratio for decaying learning rate\n",
    "           every epoch\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate_decay = learning_rate_decay\n",
    "\n",
    "        self.optimizers = None\n",
    "\n",
    "    def setup_optimizers(self):\n",
    "        params = self.model.params()\n",
    "        self.optimizers = {}\n",
    "        for param_name, param in params.items():\n",
    "            self.optimizers[param_name] = deepcopy(self.optim)\n",
    "\n",
    "    def compute_accuracy(self, X, y):\n",
    "        \"\"\"\n",
    "        Computes accuracy on provided data using mini-batches\n",
    "        \"\"\"\n",
    "        indices = np.arange(X.shape[0])\n",
    "        sections = np.arange(self.batch_size, X.shape[0], self.batch_size)\n",
    "        batches_indices = np.array_split(indices, sections)\n",
    "\n",
    "        pred = np.zeros_like(y)\n",
    "\n",
    "        for batch_indices in batches_indices:\n",
    "            batch_X = X[batch_indices]\n",
    "            pred_batch = self.model.predict(batch_X)\n",
    "            pred[batch_indices] = pred_batch\n",
    "\n",
    "        return multiclass_accuracy(pred, y)\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Trains a model\n",
    "        \"\"\"\n",
    "        if self.optimizers is None:\n",
    "            self.setup_optimizers()\n",
    "\n",
    "        num_train = self.dataset.train_X.shape[0]\n",
    "\n",
    "        loss_history = []\n",
    "        train_acc_history = []\n",
    "        val_acc_history = []\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            shuffled_indices = np.arange(num_train)\n",
    "            np.random.shuffle(shuffled_indices)\n",
    "            sections = np.arange(self.batch_size, num_train, self.batch_size)\n",
    "            batches_indices = np.array_split(shuffled_indices, sections)\n",
    "\n",
    "            batch_losses = []\n",
    "\n",
    "            for batch_indices in batches_indices:\n",
    "                # TODO Generate batches based on batch_indices and\n",
    "                # use model to generate loss and gradients for all\n",
    "                # the params\n",
    "                train_X_batch = self.dataset.train_X[batch_indices]\n",
    "                train_y_batch = self.dataset.train_y[batch_indices]\n",
    "                loss = self.model.compute_loss_and_gradients(train_X_batch, train_y_batch)\n",
    "\n",
    "                for param_name, param in self.model.params().items():\n",
    "                    optimizer = self.optimizers[param_name]\n",
    "                    param.value = optimizer.update(param.value, param.grad, self.learning_rate)\n",
    "\n",
    "                batch_losses.append(loss)\n",
    "\n",
    "            if np.not_equal(self.learning_rate_decay, 1.0):\n",
    "                # TODO: Implement learning rate decay\n",
    "                self.learning_rate *= self.learning_rate_decay\n",
    "\n",
    "            ave_loss = np.mean(batch_losses)\n",
    "\n",
    "            train_accuracy = self.compute_accuracy(self.dataset.train_X,\n",
    "                                                   self.dataset.train_y)\n",
    "\n",
    "            val_accuracy = self.compute_accuracy(self.dataset.val_X,\n",
    "                                                 self.dataset.val_y)\n",
    "\n",
    "            print(\"Loss: %f, Train accuracy: %f, val accuracy: %f\" %\n",
    "                  (batch_losses[-1], train_accuracy, val_accuracy))\n",
    "\n",
    "            loss_history.append(ave_loss)\n",
    "            train_acc_history.append(train_accuracy)\n",
    "            val_acc_history.append(val_accuracy)\n",
    "\n",
    "        return loss_history, train_acc_history, val_acc_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 38.788797, Train accuracy: 0.291222, val accuracy: 0.296000\n",
      "Loss: 34.581970, Train accuracy: 0.509333, val accuracy: 0.521000\n",
      "Loss: 38.183085, Train accuracy: 0.524556, val accuracy: 0.519000\n",
      "Loss: 39.485359, Train accuracy: 0.483333, val accuracy: 0.490000\n",
      "Loss: 40.103090, Train accuracy: 0.536889, val accuracy: 0.557000\n",
      "Loss: 35.628242, Train accuracy: 0.569889, val accuracy: 0.569000\n",
      "Loss: 36.098885, Train accuracy: 0.596333, val accuracy: 0.588000\n",
      "Loss: 43.473027, Train accuracy: 0.512111, val accuracy: 0.505000\n",
      "Loss: 37.037030, Train accuracy: 0.560556, val accuracy: 0.557000\n",
      "Loss: 29.349726, Train accuracy: 0.594222, val accuracy: 0.589000\n",
      "Loss: 28.589663, Train accuracy: 0.562000, val accuracy: 0.535000\n",
      "Loss: 33.786232, Train accuracy: 0.567444, val accuracy: 0.561000\n",
      "Loss: 44.761444, Train accuracy: 0.572667, val accuracy: 0.548000\n",
      "Loss: 30.653142, Train accuracy: 0.602444, val accuracy: 0.602000\n",
      "Loss: 29.251393, Train accuracy: 0.573556, val accuracy: 0.556000\n",
      "Loss: 34.133091, Train accuracy: 0.619000, val accuracy: 0.605000\n",
      "Loss: 25.392463, Train accuracy: 0.573556, val accuracy: 0.541000\n",
      "Loss: 41.844217, Train accuracy: 0.617111, val accuracy: 0.601000\n",
      "Loss: 29.558674, Train accuracy: 0.585889, val accuracy: 0.560000\n",
      "Loss: 35.127121, Train accuracy: 0.602667, val accuracy: 0.566000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11b486ac0>]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    Implements vanilla SGD update\n",
    "    \"\"\"\n",
    "    def update(self, w, d_w, learning_rate):\n",
    "        \"\"\"\n",
    "        Performs SGD update\n",
    "\n",
    "        Arguments:\n",
    "        w, np array - weights\n",
    "        d_w, np array, same shape as w - gradient\n",
    "        learning_rate, float - learning rate\n",
    "\n",
    "        Returns:\n",
    "        updated_weights, np array same shape as w\n",
    "        \"\"\"\n",
    "        return w - d_w * learning_rate\n",
    "\n",
    "\n",
    "class MomentumSGD:\n",
    "    \"\"\"\n",
    "    Implements Momentum SGD update\n",
    "    \"\"\"\n",
    "    def __init__(self, momentum=0.9):\n",
    "        self.momentum = 0.9\n",
    "        self.velocity = 0.\n",
    "    \n",
    "    def update(self, w, d_w, learning_rate):\n",
    "        \"\"\"\n",
    "        Performs Momentum SGD update\n",
    "\n",
    "        Arguments:\n",
    "        w, np array - weights\n",
    "        d_w, np array, same shape as w - gradient\n",
    "        learning_rate, float - learning rate\n",
    "\n",
    "        Returns:\n",
    "        updated_weights, np array same shape as w\n",
    "        \"\"\"\n",
    "        # TODO Implement momentum update\n",
    "        # Hint: you'll need to introduce some variables to remember\n",
    "        # velocity from the previous updates\n",
    "        self.velocity = self.momentum * self.velocity - learning_rate * d_w\n",
    "        return w + self.velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 43.857483, Train accuracy: 0.342111, val accuracy: 0.359000\n",
      "Loss: 34.687301, Train accuracy: 0.501556, val accuracy: 0.508000\n",
      "Loss: 38.078841, Train accuracy: 0.566667, val accuracy: 0.551000\n",
      "Loss: 33.205475, Train accuracy: 0.610889, val accuracy: 0.578000\n",
      "Loss: 32.146802, Train accuracy: 0.569000, val accuracy: 0.560000\n",
      "Loss: 35.615097, Train accuracy: 0.591778, val accuracy: 0.586000\n",
      "Loss: 32.021189, Train accuracy: 0.621556, val accuracy: 0.614000\n",
      "Loss: 36.386294, Train accuracy: 0.594111, val accuracy: 0.582000\n",
      "Loss: 29.512769, Train accuracy: 0.590667, val accuracy: 0.581000\n",
      "Loss: 33.818260, Train accuracy: 0.525889, val accuracy: 0.545000\n",
      "Loss: 29.252114, Train accuracy: 0.608667, val accuracy: 0.599000\n",
      "Loss: 26.938574, Train accuracy: 0.627778, val accuracy: 0.611000\n",
      "Loss: 40.321376, Train accuracy: 0.498778, val accuracy: 0.494000\n",
      "Loss: 31.402516, Train accuracy: 0.639444, val accuracy: 0.622000\n",
      "Loss: 41.973961, Train accuracy: 0.563667, val accuracy: 0.567000\n",
      "Loss: 39.165956, Train accuracy: 0.617667, val accuracy: 0.586000\n",
      "Loss: 30.753545, Train accuracy: 0.613111, val accuracy: 0.600000\n",
      "Loss: 33.553747, Train accuracy: 0.656000, val accuracy: 0.649000\n",
      "Loss: 33.456546, Train accuracy: 0.630667, val accuracy: 0.621000\n",
      "Loss: 31.873680, Train accuracy: 0.647000, val accuracy: 0.631000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 46.923704, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 43.937362, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 42.467947, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 44.817642, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 43.703310, Train accuracy: 0.210889, val accuracy: 0.215000\n",
      "Loss: 44.685016, Train accuracy: 0.250778, val accuracy: 0.253000\n",
      "Loss: 43.820789, Train accuracy: 0.266667, val accuracy: 0.266000\n",
      "Loss: 44.991675, Train accuracy: 0.281444, val accuracy: 0.282000\n",
      "Loss: 42.414458, Train accuracy: 0.318556, val accuracy: 0.315000\n",
      "Loss: 34.576347, Train accuracy: 0.373556, val accuracy: 0.366000\n",
      "Loss: 39.035691, Train accuracy: 0.406444, val accuracy: 0.389000\n",
      "Loss: 40.551145, Train accuracy: 0.442667, val accuracy: 0.431000\n",
      "Loss: 34.782584, Train accuracy: 0.453444, val accuracy: 0.445000\n",
      "Loss: 31.898344, Train accuracy: 0.501222, val accuracy: 0.494000\n",
      "Loss: 36.331255, Train accuracy: 0.524222, val accuracy: 0.517000\n",
      "Loss: 35.300216, Train accuracy: 0.537111, val accuracy: 0.538000\n",
      "Loss: 29.972048, Train accuracy: 0.567111, val accuracy: 0.558000\n",
      "Loss: 26.286023, Train accuracy: 0.587333, val accuracy: 0.577000\n",
      "Loss: 31.668681, Train accuracy: 0.601000, val accuracy: 0.591000\n",
      "Loss: 30.239006, Train accuracy: 0.615000, val accuracy: 0.605000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.546386, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.581033, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.429926, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.511984, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 11.415357, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 11.446580, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 11.474375, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 11.404837, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 11.275919, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 11.413152, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 11.289136, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 11.163226, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 11.059848, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 10.919125, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 11.488796, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 11.194001, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 9.945681, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 10.156606, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 9.276394, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 9.612686, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 11.050142, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 10.932851, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 10.383229, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 8.821379, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 8.945607, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 7.000279, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 5.819066, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 10.806855, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 8.963890, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 9.660694, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 7.123172, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 6.317762, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 7.184682, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 7.378051, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 5.952008, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 6.489093, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 7.124247, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 8.885426, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 7.069804, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 7.782066, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 6.950242, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 8.357208, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 5.189183, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 6.135334, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 9.943939, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 8.109797, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 7.846574, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 8.267228, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 6.882223, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 6.878556, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 5.332568, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 6.706334, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 6.000634, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 5.199900, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 4.650702, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 5.944929, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 6.081200, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 9.371872, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 6.020767, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 3.154264, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 4.855387, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 4.166722, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 4.457757, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 4.344434, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 5.808850, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 5.113697, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 6.398903, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.701540, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 4.185113, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 3.832367, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 6.053347, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 3.493296, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 3.491011, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 5.828433, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 5.888578, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 4.013066, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 7.080766, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 3.521817, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 3.099657, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 3.443710, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 5.269093, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 6.310402, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 3.372326, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 4.940563, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 3.051675, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 5.112391, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 4.537833, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.603922, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 4.343166, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.927750, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 5.966032, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 4.313088, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 4.618923, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 3.146070, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.615297, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.897802, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.435058, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.632833, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.592247, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.219687, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 3.265855, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 2.256887, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 2.670558, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 2.477280, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.767098, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 3.285422, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 2.806269, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.622755, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.848110, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.859039, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.308857, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.331780, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 3.217880, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.187555, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.632112, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.020426, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 3.442054, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.356959, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.863989, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 3.188357, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.894843, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.221881, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.681309, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.781782, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.853542, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.653903, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.714078, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.927856, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.572225, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.140434, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.858690, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.658306, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.015812, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.129875, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.991063, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.821753, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.829974, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.534522, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.833015, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.211252, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.946496, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.873620, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.147194, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.874260, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.184137, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.861341, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.086669, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.967441, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.354552, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.346518, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "num_epochs = 150\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-2, num_epochs=num_epochs, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 34.536834, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 33.700228, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 32.619223, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 28.333945, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 23.539553, Train accuracy: 0.400000, val accuracy: 0.133333\n",
      "Loss: 24.309329, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 30.342126, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 34.640622, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 74.867586, Train accuracy: 0.266667, val accuracy: 0.200000\n",
      "Loss: 223.574746, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: 216.439947, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 111.986009, Train accuracy: 0.466667, val accuracy: 0.333333\n",
      "Loss: 190.227188, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 43.060457, Train accuracy: 0.666667, val accuracy: 0.200000\n",
      "Loss: 17.460487, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Loss: 23.940725, Train accuracy: 0.866667, val accuracy: 0.200000\n",
      "Loss: 9.476695, Train accuracy: 0.933333, val accuracy: 0.133333\n",
      "Loss: 10.370508, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Loss: 3.145240, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Loss: 2.626286, Train accuracy: 1.000000, val accuracy: 0.133333\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "num_epochs = 20\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 300, reg = 1e-3)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=0.1, num_epochs=num_epochs, batch_size=15,\n",
    "                 learning_rate_decay=0.92)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 88.687688, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 88.061177, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 89.472635, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 91.814047, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 82.001368, Train accuracy: 0.212778, val accuracy: 0.221000\n",
      "Loss: 81.864798, Train accuracy: 0.264667, val accuracy: 0.265000\n",
      "Loss: 77.033199, Train accuracy: 0.296000, val accuracy: 0.298000\n",
      "Loss: 77.601747, Train accuracy: 0.357778, val accuracy: 0.361000\n",
      "Loss: 52.032447, Train accuracy: 0.418444, val accuracy: 0.413000\n",
      "Loss: 61.035997, Train accuracy: 0.470000, val accuracy: 0.445000\n",
      "Loss: 68.823540, Train accuracy: 0.513111, val accuracy: 0.504000\n",
      "Loss: 58.323819, Train accuracy: 0.534444, val accuracy: 0.531000\n",
      "Loss: 50.007609, Train accuracy: 0.582111, val accuracy: 0.569000\n",
      "Loss: 52.249678, Train accuracy: 0.616222, val accuracy: 0.594000\n",
      "Loss: 43.325887, Train accuracy: 0.630444, val accuracy: 0.620000\n",
      "Loss: 54.550175, Train accuracy: 0.650222, val accuracy: 0.635000\n",
      "Loss: 55.470970, Train accuracy: 0.671556, val accuracy: 0.651000\n",
      "Loss: 50.795905, Train accuracy: 0.688111, val accuracy: 0.675000\n",
      "Loss: 35.699145, Train accuracy: 0.697556, val accuracy: 0.685000\n",
      "Loss: 47.516368, Train accuracy: 0.706444, val accuracy: 0.686000\n",
      "Loss: 54.043233, Train accuracy: 0.712222, val accuracy: 0.694000\n",
      "Loss: 33.492364, Train accuracy: 0.724778, val accuracy: 0.694000\n",
      "Loss: 38.229055, Train accuracy: 0.728778, val accuracy: 0.693000\n",
      "Loss: 38.090356, Train accuracy: 0.732556, val accuracy: 0.691000\n",
      "Loss: 30.785178, Train accuracy: 0.752333, val accuracy: 0.704000\n",
      "Loss: 41.522750, Train accuracy: 0.756111, val accuracy: 0.703000\n",
      "Loss: 26.065839, Train accuracy: 0.757333, val accuracy: 0.711000\n",
      "Loss: 32.839888, Train accuracy: 0.765000, val accuracy: 0.730000\n",
      "Loss: 44.428210, Train accuracy: 0.775111, val accuracy: 0.725000\n",
      "Loss: 30.373134, Train accuracy: 0.778000, val accuracy: 0.732000\n",
      "Loss: 49.673744, Train accuracy: 0.771222, val accuracy: 0.713000\n",
      "Loss: 26.754440, Train accuracy: 0.786556, val accuracy: 0.730000\n",
      "Loss: 26.401176, Train accuracy: 0.791889, val accuracy: 0.727000\n",
      "Loss: 30.359920, Train accuracy: 0.796333, val accuracy: 0.736000\n",
      "Loss: 29.749918, Train accuracy: 0.790222, val accuracy: 0.714000\n",
      "Loss: 31.070865, Train accuracy: 0.795444, val accuracy: 0.732000\n",
      "Loss: 26.454481, Train accuracy: 0.815222, val accuracy: 0.746000\n",
      "Loss: 23.040348, Train accuracy: 0.820111, val accuracy: 0.739000\n",
      "Loss: 36.386589, Train accuracy: 0.819778, val accuracy: 0.742000\n",
      "Loss: 34.632369, Train accuracy: 0.825444, val accuracy: 0.746000\n",
      "Loss: 23.836139, Train accuracy: 0.829111, val accuracy: 0.746000\n",
      "Loss: 18.420625, Train accuracy: 0.835556, val accuracy: 0.753000\n",
      "Loss: 26.582170, Train accuracy: 0.845889, val accuracy: 0.757000\n",
      "Loss: 16.941181, Train accuracy: 0.842000, val accuracy: 0.757000\n",
      "Loss: 33.461084, Train accuracy: 0.847222, val accuracy: 0.746000\n",
      "Loss: 16.922073, Train accuracy: 0.844000, val accuracy: 0.739000\n",
      "Loss: 23.011142, Train accuracy: 0.852556, val accuracy: 0.752000\n",
      "Loss: 27.950852, Train accuracy: 0.859444, val accuracy: 0.750000\n",
      "Loss: 19.193020, Train accuracy: 0.857778, val accuracy: 0.758000\n",
      "Loss: 22.377502, Train accuracy: 0.868556, val accuracy: 0.760000\n",
      "best validation accuracy achieved: 0.760000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-2\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "momentum = 0.9\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "best_loss_history = []\n",
    "best_train_history = []\n",
    "best_val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, \n",
    "                    hidden_layer_size = hidden_layer_size, reg = reg_strength)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(momentum), learning_rate=learning_rates, \n",
    "                  learning_rate_decay=learning_rate_decay, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "val_multiclass_accuracy = multiclass_accuracy(model.predict(val_X), val_y)\n",
    "\n",
    "if val_multiclass_accuracy > 0.6:\n",
    "    best_val_accuracy = val_multiclass_accuracy\n",
    "    best_classifier = model\n",
    "    best_loss_history = loss_history\n",
    "    best_train_history = train_history\n",
    "    best_val_history = val_history\n",
    "    \n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11afbd220>]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(best_loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(best_train_history)\n",
    "plt.plot(best_val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.729000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
